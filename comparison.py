# -*- coding: utf-8 -*-
"""methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b5JnzUKwtOWXzbefdhPLFbpXGq_kVW_o
"""

import re
import numpy as np
import gensim

from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.metrics import f1_score

import gensim.downloader as api

def clean_text(text):
    words=text.split()
    words2=[]
    for i in words:
        if 'http' not in i and '\\' not in i and '@' not in i:
            words2.append(i)
        if '\\u2019' in i:
            words2.append(i.replace('\u2019','\''))
    for i in words2[::-1]:
        if '#' in i:
            words2.remove(i)
        if '#' not in i:
            break
    sentence=''
    for i in words2:
        sentence=sentence+i+' '
    sentence=sentence.replace('#','')
    return sentence

def get_data(filename):
    f=open(filename)
    a=f.read()
    f.close()

    b=a.split('\n')[:-1]
    x={}
    y={}
    for i in b[1:]:
        x[i.split('\t')[0]]=i.split('\t')[1]
        y[i.split('\t')[0]]=i.split('\t')[2]

    for i in x:
        x[i]=clean_text(x[i]).lower()

    words_to_int={}
    num=1
    sentences_to_int=[]
    result=[]
    for i in x:
        sentence=x[i]
        words=re.findall(r'\w+',x[i])
        sentence_to_int=[]
        for word in words:
            try:
                sentence_to_int.append(model[word])
            except:
                continue
        sentences_to_int.append(sentence_to_int)
        result.append(y[i])

    for i in sentences_to_int:
        if len(i)<80:
            for j in range(0,80-len(i)):
                i.append(np.full((25,),0))

    x_train=[]
    for i in sentences_to_int:
        x_train.append(np.array(i).reshape(80*25))

    #x_train=sentences_to_int
    y_train=result
    return x_train,y_train

#model = gensim.models.KeyedVectors.load_word2vec_format('gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)
import gensim.downloader as api
model = api.load("glove-twitter-25")

datasets=os.listdir('SemEval-2019-Task-6-master/training/')
for dataset in datasets:
    if '.tsv' not in dataset:
        continue
    print(dataset)
    x_train,y_train=get_data('SemEval-2019-Task-6-master/training/'+dataset)
    x_test,y_test=get_data('SemEval-2019-Task-6-master/testing/'+dataset.replace('train','test'))
    
    gnb = GaussianNB()
    y_pred = gnb.fit(x_train, y_train).predict(x_test)
    print('The F1-score of Naive Bayes is '+str(f1_score(list(map(int, y_test)),list(map(int, y_pred)), zero_division=1)))
    
    clf = LogisticRegression(random_state=0)
    y_pred = clf.fit(x_train, y_train).predict(x_test)
    print('The F1-score of Logistic Regression is '+str(f1_score(list(map(int, y_test)),list(map(int, y_pred)), zero_division=1)))
    
    svc = svm.LinearSVC()
    y_pred =svc.fit(x_train, y_train).predict(x_test)
    print('The F1-score of svm is '+str(f1_score(list(map(int, y_test)),list(map(int, y_pred)), zero_division=1)))

